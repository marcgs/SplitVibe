---
name: validate-pr
description: >
  Validates a PR's acceptance criteria using the most appropriate strategy:
  browser-based E2E tests (Playwright MCP), API calls, CLI/terminal commands,
  or unit test execution. Reads the linked GitHub issue as the single source
  of truth for acceptance criteria.
---

# Validate PR Acceptance Criteria

Validate the acceptance criteria of the given PR.

## Input

A pull request number or URL from the **marcgs/SplitVibe** repository.

## Steps

### 1. Resolve the PR and linked GitHub issue

- Fetch the PR description from **GitHub**.
- Look for a `Closes #N`, `Fixes #N`, or `Resolves #N` reference in the PR
  body or in the linked issues sidebar.
- Open that **GitHub Issue** and extract the **Acceptance Criteria** checklist
  items verbatim.
- **GitHub is the single source of truth** â€” do not fall back to local
  markdown files.
- If no linked issue or acceptance criteria can be found, report an error and
  stop.

### 2. Classify each acceptance criterion

For every acceptance criterion, assign **one or more** validation
strategies. A single criterion can (and often should) be validated
through multiple complementary strategies.

Available strategies:

- **ğŸŒ Browser (E2E)** â€” Criterion has **any** observable UI impact:
  pages, forms, navigation, lists, toasts, modals, visual feedback.
  Validate with Playwright MCP browser tools against
  `http://localhost:3000`.
- **ğŸ”Œ API** â€” Criterion involves HTTP endpoints (status codes,
  response shapes, auth guards). Validate with `curl`/`fetch`
  against `http://localhost:3000/api/â€¦`.
- **ğŸ§ª Unit / Integration test** â€” Criterion involves logic, schema,
  data transformations, or domain rules. Run `npx vitest run <path>`
  or `npm test`. Note gaps if no tests exist.
- **ğŸ› ï¸ CLI / Infrastructure** â€” Criterion involves DB state,
  migrations, Prisma schema, env config, Docker, or files. Run the
  appropriate CLI command and inspect output.
- **ğŸ“„ Code review** â€” Criterion involves code quality, patterns, or
  architectural constraints. Inspect the PR diff and run
  `npm run typecheck` and `npm run lint`.

> **ğŸŒ Browser-first rule:** If a criterion mentions user-visible
> behavior â€” submitting a form, seeing a list, viewing data on a page,
> receiving feedback, navigating between views â€” it **MUST** include
> ğŸŒ Browser (E2E) as a strategy, even if unit tests also cover the
> underlying logic. Unit or integration tests alone are **never** a
> substitute for browser validation of UI-facing criteria.
> Passing unit tests does not verify that the UI renders correctly,
> handles user interaction, or integrates end-to-end.

### 3. Start a clean dev environment

Always start from a **clean slate** to avoid stale state, old code, or
leftover data from previous runs.

1. **Tear down anything already running:**
   - Kill any process on port 3000
     (`lsof -ti:3000 | xargs kill 2>/dev/null`).
   - `docker compose down -v` â€” stop and remove all containers and
     volumes.
2. **Start backend services:**
   - `docker compose up -d db storage` â€” start Postgres and Azurite.
   - Wait for Postgres to be ready
     (`docker compose exec db pg_isready -U postgres`; retry if needed).
3. **Apply migrations:**
   - `npx prisma migrate dev` â€” apply pending migrations to a fresh DB.
4. **Start the Next.js dev server** (async/detached so it keeps running):
   - `npm run dev`
5. **Wait for the server to be ready:**
   - Poll `curl -sf http://localhost:3000` with retries (up to ~30 s).
   - If it still fails after retries, mark browser/API criteria as
     â­ï¸ **Blocked** and continue with other strategies.

**Additional prerequisites:**

- **For ğŸ§ª Unit/Integration criteria:** verify `node_modules` exists
  (run `npm ls vitest` to confirm).
- **For ğŸ› ï¸ CLI/Infrastructure criteria:** the Docker services started
  above cover database access.

Only stop for the strategies that are blocked â€” continue validating criteria
that have their prerequisites met.

### 4. Validate each criterion

Execute each criterion using its assigned strategy:

#### ğŸŒ Browser (E2E)

1. Navigate to the relevant page or flow.
2. Wait for the page to be fully loaded (key selector visible / network idle).
3. Interact as a real user â€” fill forms, click buttons, follow redirects.
4. Assert expected outcomes: elements appear/disappear, messages shown, URL
   changes, no JS console errors.
5. Capture a screenshot via `browser_take_screenshot` after each key assertion.

#### ğŸ”Œ API

1. Construct the request (method, path, headers, body).
2. Execute via terminal: `curl -s -w "\n%{http_code}" -X METHOD URL`.
3. Assert: status code, response body shape, error messages, headers.
4. For authenticated endpoints, include the session token/cookie if available.

#### ğŸ§ª Unit / Integration test

1. Identify the test file(s) covering the criterion.
2. Run: `npx vitest run <path/to/test.ts>`.
3. Assert: all relevant tests pass with zero failures.
4. If no tests exist for the criterion, report as
   âš ï¸ **GAP â€” no test coverage found**.

#### ğŸ› ï¸ CLI / Infrastructure

1. Run the relevant command in the terminal.
2. Assert: expected output, exit code 0, files exist, schema is valid, etc.
3. Capture terminal output as evidence.

#### ğŸ“„ Code review

1. Inspect the PR diff for the relevant files.
2. Run `npm run typecheck` and `npm run lint`.
3. Assert: no errors, patterns match the criterion requirements.

### 5. On failure

- Record the failing assertion, evidence (screenshot or terminal output), and
  context (URL, command, test name).
- **Continue** with remaining criteria â€” do not abort the entire run.

### 6. Report results

```markdown
## Validation Report â€” PR #<number>

### Issue: <issue title> (#<issue number>)

| # | Criterion | Strategy | Result | Notes |
|---|-----------|----------|--------|-------|
| 1 | <text> | ğŸŒ Browser + ğŸ§ª Unit | âœ… PASS | Screenshot: <ref>, 3/3 tests pass |
| 2 | <text> | ğŸ”Œ API | âŒ FAIL | Expected 201, got 500 |
| 3 | <text> | ğŸ§ª Unit test | âœ… PASS | 5/5 passed |
| 4 | <text> | ğŸ› ï¸ CLI | âœ… PASS | Exit code 0 |
| 5 | <text> | ğŸ“„ Review | âœ… PASS | Typecheck clean |
| 6 | <text> | ğŸŒ Browser + ğŸ§ª Unit | â­ï¸ BLOCKED | Browser: dev server down; Unit: 2/2 pass |

### Summary

- âœ… **Passed:** X
- âŒ **Failed:** Y
- âš ï¸ **Gaps:** Z (no test coverage)
- â­ï¸ **Blocked:** W (prerequisites not met)
```

**Final conclusion â€” use exactly one of:**

- âœ… **All acceptance criteria for this PR are verified.**
- âŒ **Some acceptance criteria failed validation. See details above.**
- âš ï¸ **All criteria passed but some have no test coverage.
  Consider adding tests.**

### 7. Post results to the PR

After producing the validation report, **post it as a comment on the
PR in GitHub**. Use the GitHub API (or the available GitHub MCP tools)
to add an issue comment on the pull request with the full report from
step 6.

- If a previous validation comment from this agent already exists on
  the PR, **update it** instead of creating a duplicate.
- The comment should contain the complete report table, summary, and
  conclusion so that reviewers can see the validation status directly
  in the PR timeline without re-running the agent.

### 8. Tear down the dev environment

After posting results, **always** clean up:

1. Stop the Next.js dev server (kill the process on port 3000).
2. `docker compose down -v` â€” stop and remove all containers and volumes.
